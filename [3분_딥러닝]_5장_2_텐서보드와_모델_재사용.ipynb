{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[3분 딥러닝] 5장-2 - 텐서보드와 모델 재사용.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihyunjeongme/deeplearning-tensflow-3min/blob/master/%5B3%EB%B6%84_%EB%94%A5%EB%9F%AC%EB%8B%9D%5D_5%EC%9E%A5_2_%ED%85%90%EC%84%9C%EB%B3%B4%EB%93%9C%EC%99%80_%EB%AA%A8%EB%8D%B8_%EC%9E%AC%EC%82%AC%EC%9A%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_CHGVuo-tIl",
        "colab_type": "code",
        "outputId": "a60e0f5f-84ce-4905-c71d-8e1f33894926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rf1uWuo-wlb",
        "colab_type": "code",
        "outputId": "fbc62919-2c06-4472-c55f-3639c7d5d7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/gdrive/My Drive/Colab Notebooks/deeplearning-tensorflow-3mins"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/deeplearning-tensorflow-3mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmS0GEmNWPod",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 텐서보드는 학습 과정을 추정하는 데 용이\n",
        "# 학습하는 중간중간 손실값이나 정확도 또는 결로 나온 이미지나 사운드 파일들을\n",
        "# 다양한 방식으로 시각화해 보여줌"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4H6McmO-wvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 먼저 데이터를 읽어 들이는 코드와 플레이스홀더 값들을 똑같이 넣어줌\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "data = np.loadtxt('./data.csv', delimiter=',',\n",
        "                 unpack=True, dtype='float32')\n",
        "\n",
        "x_data = np.transpose(data[0:2])\n",
        "y_data = np.transpose(data[2:])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByEvI0iA-w10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui1Q1YMS-hAM",
        "colab_type": "code",
        "outputId": "70da7936-0c19-4bea-82d8-220dfe135a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1839
        }
      },
      "source": [
        "\n",
        "#########\n",
        "# 신경망 모델 구성\n",
        "######\n",
        "\n",
        "# 신경망 모델을 구성할 차례\n",
        "# 학습 횟수를 카운트 하는 변수(학습에 직접 사용되지는 않음)\n",
        "# 변수 정의 시 trainable=False라는 옵션을 줌\n",
        "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
        "\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "# 신경망의 각 계층에 다음 코드를 덧붙여 줍니다.\n",
        "# with tf.name_scope로 묶은 블록은 텐서보드에서 한 계층 내부를 표현\n",
        "# name='W1' 이름 붙이면 텐서보드에서 해당 이름의 변수가 어디서 사용되는지 쉽게 확인\n",
        "# 이름은 변수뿐만 아니라 플레이스 홀더, 각각의 연산, 활성화 함수 등 모든 텐서에 붙일 수 있음\n",
        "\n",
        "\n",
        "# 이렇게 다른 계층들도 전부 tf.name_scope로 묶어주고 이름도 붙여줌\n",
        "with tf.name_scope('layer1'):\n",
        "    W1 = tf.Variable(tf.random_uniform([2, 10], -1., 1.), name='W1')\n",
        "    L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "    tf.summary.histogram(\"X\", X)\n",
        "    tf.summary.histogram(\"Weights\", W1)\n",
        "\n",
        "with tf.name_scope('layer2'):\n",
        "    W2 = tf.Variable(tf.random_uniform([10, 20], -1., 1.), name='W2')\n",
        "    L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "    tf.summary.histogram(\"Weights\", W2)\n",
        "\n",
        "with tf.name_scope('output'):\n",
        "    W3 = tf.Variable(tf.random_uniform([20, 3], -1., 1.), name='W3')\n",
        "    model = tf.matmul(L2, W3)\n",
        "\n",
        "    tf.summary.histogram(\"Weights\", W3)\n",
        "    tf.summary.histogram(\"Model\", model)\n",
        "\n",
        "with tf.name_scope('optimizer'):\n",
        "    cost = tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=model))\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
        "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
        "\n",
        "# 손실값을 추적하기 위해 수집할 값을 지정하는 코드 작성\n",
        "# tf.summary 모듈의 scalar 함수는 값이 하나인 텐서를 수집할 떄 사용\n",
        "    tf.summary.scalar('cost', cost)\n",
        "\n",
        "\n",
        "#########\n",
        "# 신경망 모델 학습\n",
        "######\n",
        "\n",
        "\n",
        "# 모델을 불러들이거나 초기화\n",
        "sess = tf.Session()\n",
        "saver = tf.train.Saver(tf.global_variables())\n",
        "\n",
        "\n",
        "# ./model 디렉터리에 기존에 학습해둔 모델이 있는지를 확인해서 \n",
        "# 모델이 있다면 saver.restore 함수를 사용해 학습된 값들을 불러오고,\n",
        "# 아니면 변수를 새로 초기화\n",
        "# 학습된 모델을 저장한 파일을 체크포인트 파일 이라고 함\n",
        "\n",
        "ckpt = tf.train.get_checkpoint_state('./model')\n",
        "if ckpt and tf.train.checkpoint_exists(ckpt.model_checkpoint_path):\n",
        "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "else:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "# tf.summary.merge_all 함수로 앞서 지정한 텐서들을 수집한 다음\n",
        "# tf.summary.FileWriter 함수를 이용해 그래프와 텐서들의 값을 저장할 디텍터리 설정\n",
        "merged = tf.summary.merge_all()\n",
        "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
        "\n",
        "\n",
        "# 최적화를 실행하는 코드를 앞서와 같이 작성\n",
        "for step in range(100):\n",
        "    sess.run(train_op, feed_dict={X: x_data, Y: y_data})\n",
        "\n",
        "    print('Step: %d, ' % sess.run(global_step),\n",
        "          'Cost: %.3f' % sess.run(cost, feed_dict={X: x_data, Y: y_data}))\n",
        "\n",
        "    summary = sess.run(merged, feed_dict={X: x_data, Y: y_data})\n",
        "    writer.add_summary(summary, global_step=sess.run(global_step))\n",
        "\n",
        "saver.save(sess, './model/dnn.ckpt', global_step=global_step)\n",
        "\n",
        "#########\n",
        "# 결과 확인\n",
        "######\n",
        "prediction = tf.argmax(model, 1)\n",
        "target = tf.argmax(Y, 1)\n",
        "print('예측값:', sess.run(prediction, feed_dict={X: x_data}))\n",
        "print('실제값:', sess.run(target, feed_dict={Y: y_data}))\n",
        "\n",
        "is_correct = tf.equal(prediction, target)\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도: %.2f' % sess.run(accuracy * 100, feed_dict={X: x_data, Y: y_data}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Step: 1,  Cost: 1.020\n",
            "Step: 2,  Cost: 0.963\n",
            "Step: 3,  Cost: 0.915\n",
            "Step: 4,  Cost: 0.873\n",
            "Step: 5,  Cost: 0.835\n",
            "Step: 6,  Cost: 0.803\n",
            "Step: 7,  Cost: 0.776\n",
            "Step: 8,  Cost: 0.754\n",
            "Step: 9,  Cost: 0.735\n",
            "Step: 10,  Cost: 0.720\n",
            "Step: 11,  Cost: 0.706\n",
            "Step: 12,  Cost: 0.694\n",
            "Step: 13,  Cost: 0.683\n",
            "Step: 14,  Cost: 0.673\n",
            "Step: 15,  Cost: 0.663\n",
            "Step: 16,  Cost: 0.655\n",
            "Step: 17,  Cost: 0.647\n",
            "Step: 18,  Cost: 0.640\n",
            "Step: 19,  Cost: 0.634\n",
            "Step: 20,  Cost: 0.628\n",
            "Step: 21,  Cost: 0.623\n",
            "Step: 22,  Cost: 0.618\n",
            "Step: 23,  Cost: 0.614\n",
            "Step: 24,  Cost: 0.609\n",
            "Step: 25,  Cost: 0.605\n",
            "Step: 26,  Cost: 0.601\n",
            "Step: 27,  Cost: 0.596\n",
            "Step: 28,  Cost: 0.592\n",
            "Step: 29,  Cost: 0.588\n",
            "Step: 30,  Cost: 0.585\n",
            "Step: 31,  Cost: 0.581\n",
            "Step: 32,  Cost: 0.579\n",
            "Step: 33,  Cost: 0.576\n",
            "Step: 34,  Cost: 0.574\n",
            "Step: 35,  Cost: 0.572\n",
            "Step: 36,  Cost: 0.570\n",
            "Step: 37,  Cost: 0.568\n",
            "Step: 38,  Cost: 0.567\n",
            "Step: 39,  Cost: 0.565\n",
            "Step: 40,  Cost: 0.564\n",
            "Step: 41,  Cost: 0.563\n",
            "Step: 42,  Cost: 0.562\n",
            "Step: 43,  Cost: 0.561\n",
            "Step: 44,  Cost: 0.560\n",
            "Step: 45,  Cost: 0.559\n",
            "Step: 46,  Cost: 0.558\n",
            "Step: 47,  Cost: 0.557\n",
            "Step: 48,  Cost: 0.557\n",
            "Step: 49,  Cost: 0.556\n",
            "Step: 50,  Cost: 0.556\n",
            "Step: 51,  Cost: 0.555\n",
            "Step: 52,  Cost: 0.555\n",
            "Step: 53,  Cost: 0.555\n",
            "Step: 54,  Cost: 0.554\n",
            "Step: 55,  Cost: 0.554\n",
            "Step: 56,  Cost: 0.554\n",
            "Step: 57,  Cost: 0.553\n",
            "Step: 58,  Cost: 0.553\n",
            "Step: 59,  Cost: 0.553\n",
            "Step: 60,  Cost: 0.553\n",
            "Step: 61,  Cost: 0.552\n",
            "Step: 62,  Cost: 0.552\n",
            "Step: 63,  Cost: 0.552\n",
            "Step: 64,  Cost: 0.552\n",
            "Step: 65,  Cost: 0.552\n",
            "Step: 66,  Cost: 0.552\n",
            "Step: 67,  Cost: 0.552\n",
            "Step: 68,  Cost: 0.552\n",
            "Step: 69,  Cost: 0.551\n",
            "Step: 70,  Cost: 0.551\n",
            "Step: 71,  Cost: 0.551\n",
            "Step: 72,  Cost: 0.551\n",
            "Step: 73,  Cost: 0.551\n",
            "Step: 74,  Cost: 0.551\n",
            "Step: 75,  Cost: 0.551\n",
            "Step: 76,  Cost: 0.551\n",
            "Step: 77,  Cost: 0.551\n",
            "Step: 78,  Cost: 0.551\n",
            "Step: 79,  Cost: 0.551\n",
            "Step: 80,  Cost: 0.551\n",
            "Step: 81,  Cost: 0.551\n",
            "Step: 82,  Cost: 0.551\n",
            "Step: 83,  Cost: 0.551\n",
            "Step: 84,  Cost: 0.551\n",
            "Step: 85,  Cost: 0.551\n",
            "Step: 86,  Cost: 0.551\n",
            "Step: 87,  Cost: 0.551\n",
            "Step: 88,  Cost: 0.550\n",
            "Step: 89,  Cost: 0.550\n",
            "Step: 90,  Cost: 0.550\n",
            "Step: 91,  Cost: 0.550\n",
            "Step: 92,  Cost: 0.550\n",
            "Step: 93,  Cost: 0.550\n",
            "Step: 94,  Cost: 0.550\n",
            "Step: 95,  Cost: 0.550\n",
            "Step: 96,  Cost: 0.550\n",
            "Step: 97,  Cost: 0.550\n",
            "Step: 98,  Cost: 0.550\n",
            "Step: 99,  Cost: 0.550\n",
            "Step: 100,  Cost: 0.550\n",
            "예측값: [0 1 2 0 0 2]\n",
            "실제값: [0 1 2 0 0 2]\n",
            "정확도: 100.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_rPzxiC-o_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}