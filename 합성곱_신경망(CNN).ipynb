{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "합성곱 신경망(CNN)",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihyunjeongme/deeplearning-tensflow-3min/blob/master/%ED%95%A9%EC%84%B1%EA%B3%B1_%EC%8B%A0%EA%B2%BD%EB%A7%9D(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhSeGk2wcl0h",
        "colab_type": "text"
      },
      "source": [
        "# 합성곱 신경망(CNN)\n",
        "\n",
        "---\n",
        "\n",
        "CNN(Convolutional Neural Network)은 1998년 얀 레쿤 교수가 소개한 이래로 널리 사용되고 있는 신경망."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKZxsAa4OmWZ",
        "colab_type": "text"
      },
      "source": [
        "# 7.1 CNN 개념\n",
        "\n",
        "---\n",
        "- 입력층과 출력층 사이의 중간층(은폐층)에 합성곱층과 풀링층을 배치한 것\n",
        "- 다층퍼셉트론은 데이터를 입력하기 위해 2차원 평면에 있는 숫자를 1차원 배열로 형환을 하여 2차원 평면에서 가지고 있던 고유 데이터 정보를 잃은 채로 학습을 시작\n",
        "- 반면 CNN은 우리의 뇌가 사물을 구별하는 방법으로 생김새 정보로 사물을 학습하고 구별\n",
        "- 주로 이미지 인식, 음식 인식에 많이 사용 됨\n",
        "---\n",
        "\n",
        "- **컨볼루션 계층(합성곱 계층)과 풀링 계층으로 구성**\n",
        "- **컨볼루션 계층(합성곱 계층)** \n",
        "  - 이미지 특징을 추출 할 때 사용\n",
        "  - 입력 x의 일부분을 조금 씩 자르면서 평활화와 윤곽선 검출 처리를 하며, 특징맵을 추출\n",
        "- **풀링 계층**\n",
        "  - 합성곱층으로 얻은 특징 맵을 축소하는 층\n",
        "  - 모델 파라미터를 줄임으로 써 모델의 계산량을 줄이는 데 있음.\n",
        "- **전결합층(FC/Fully Connected)**\n",
        "  - 추출된 특징을 가지고 분류를 수행하는 레이어\n",
        "- **필터(커널)**\n",
        "  - 필터의 매개 변수가 '가중치'\n",
        "  - ex) 윈도우 크기가 3 x 3 이라면, 3 x 3개의 가중치와 1개의 편향이 필요합니다.\n",
        "  - 이 3 x 3개의 가중치와 1개의 편향을 커널 또는 필터 라고 하며\n",
        "  - 이 커널은 해당 은닉층을 만들기 위한 모든 윈도우에 공통으로 적용됩니다.\n",
        "- **스트라이드**\n",
        "  - 몇칸씩 움직일지 정하는 값\n",
        "  - 필터를 적용하는 위치의 간격\n",
        "- **패딩(Padding)**\n",
        "  - 입력 데이터 주변 값을 0으로 채움(제로패딩)\n",
        "  - 보통 스트라이드를 통해 입력된 행렬보다 작아진 행렬 출력, 제로패딩을 통해 스트라이드 이후에도 그 사이즈를 동일하게 유지\n",
        "  - 0으로 감싸진 부분이 테두리라는 정보 역시 CNN이 활용 할 수 있는 정보\n",
        "- **피쳐맵(특징맵): 스트라이드를 통해 얻어진 행렬**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "- 설계자는 필터의 개수와 형태만 정할 뿐 역활을 직접부여하진 않습니다.\n",
        "- 필터의 역활은 최적화 과정을 통해 모델이 스스로 찾아부여\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOXoyi8QQjvh",
        "colab_type": "text"
      },
      "source": [
        "# 7.2 모델 구현하기\n",
        "\n",
        "---\n",
        "\n",
        "앞 장에서 사용한 MNIST 데이터를 CNN으로 학습시키는 모델을 만들어보면서 조금 더 자세히 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHAl6aXcHzE",
        "colab_type": "code",
        "outputId": "54df3a05-c3ae-44f2-a5a2-9417392463f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-bed9dddec7b6>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybo-RdHdRK0F",
        "colab_type": "code",
        "outputId": "30d80a7d-cd27-462b-b07b-4495d7bf993b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 앞 장에서 만든 모델에서는 입력값을 28 x 28짜리 하나로 구성했지만, CNN 모델에서는 \n",
        "# 앞서 설명한 것 처럼 2차원 평면으로 구성하므로 다음처럼 조금 더 직관적인 형태로 구성할수 있음.\n",
        "\n",
        "\n",
        "# X의 첫 번째 차원인 None은 입력 데이터의 개수. 마지막 차원인 1은 특징의 개수\n",
        "# MINIST 데이터는 회색조 이미지라 채널에 색상이 한개 뿐이므로 1을 사용\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "\n",
        "# 출력값인 10개의 분류와, 드롭아웃을 위한 keep_prob 플레이스 홀더도 정의\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffdNasC_SBoT",
        "colab_type": "code",
        "outputId": "daa18a9a-5979-40c5-a68f-d2ddaadc6d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# CNN 계층을 구성\n",
        "\n",
        "# 컨볼루션 계층을 만듬(3 x 3 크기의 커널을)\n",
        "# tf.nn.conv2d 함수를 사용하면 간단하게 구성할 수 있음.\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "L1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
        "L1 = tf.nn.relu(L1)\n",
        "\n",
        "# 28 x 28 ----> 32개\n",
        "print(L1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e_tegHnSlEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력층 X와 첫 번째 계층의 가중치 W1을 가지고, 오른쪽과 아래쪽 한칸씩 움직이는 32개의 커널을 가진\n",
        "# 컨볼루션 계층을 만들겠다는 코드\n",
        "\n",
        "# padding='SAME'은 커널 슬라이딩 시 이미지의 가장 외곽에서 한 칸 밖으로 움직이는 옵션\n",
        "# 이렇게 하면 이미지의 테두리까지도 조금 더 정확하게 평가 할 수 있습니다.\n",
        "\n",
        "# tf.nn.relu 활성화 함수를 통해 컨볼루션 계층 완성"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcCwimPCZpmZ",
        "colab_type": "code",
        "outputId": "3314a6ec-cfce-4d97-c1a5-179cd60ca8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 풀링계층 만듬\n",
        "\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
        "                    padding='SAME')\n",
        "\n",
        "# 14 x 14 ----> 32개\n",
        "# 풀링계층에서 갯수가 줄음\n",
        "print(L1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7lFdv4mZ2wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 앞서 만든 컨볼루션 계층을 입력층으로 사용하고, 커널 크기를 2 x 2 로 하는 풀링 계층을 만듬\n",
        "\n",
        "# strides=[1,2,2,1] 값은 슬라이딩 시 두칸씩 움직이겠다는 옵션"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcBqPYH5aMLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 두번째 계층을 동일한 방식으로 구성\n",
        "\n",
        "# 3 x 3 크기의 커널 64개로 구성한 컬볼루션 계층과\n",
        "# 3, 3, 32, 64 여기에서 32는 앞 서 구성한 첫 번째 컨볼루션 계층의 커널 개수\n",
        "# 이것은 출력층의 개수이며 또한 첫 번째 컨볼루션 계층이 찾아낸 이미지의 특징 개수\n",
        "\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "\n",
        "# 2 x 2 크기의 풀링 계층으로 구성\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
        "                    padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1-nBGrkbrRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "424b5803-a07d-4aaa-f47f-6172b7ce0606"
      },
      "source": [
        "# 이제 추출한 특징들을 이용해 10개의 분류를 만들어내는 계층을 구성해보겠습니다.\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
        "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
        "L3 = tf.matmul(L3, W3)\n",
        "L3 = tf.nn.relu(L3)\n",
        "L3 = tf.nn.dropout(L3, keep_prob)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-09fc95f3324c>:6: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTa16iPkc91x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 먼저 10개의 분류는 1차원 배열이므로 차원을 줄이는 단계를 거쳐야 합니다.\n",
        "# 직전 풀링 계층 크기가 7 x 7 x 64 이므로 tf.reshpae 함수를 이용해 7 x 7 x 64 크기의 1차원\n",
        "# 계층으로 만들고, 이 배열 전체를 최종 출력값의 중간 단계 인 256개의 뉴런으로 연결하는 신경망을 만듬.\n",
        "\n",
        "# 이처럼 인접한 계층의 모든 뉴런과 상호 연결된 계층을 '완전연결계층' 이라고 함.\n",
        "# 이번 계층에서는 과적합을 막아주는 드롭아웃 기법 사용"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO9TUPa-d9SG",
        "colab_type": "code",
        "outputId": "d95894c6-d09b-43bd-a567-b403421e89d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 모델 구성의 마지막으로 직전의 은닉층인 L3의 출력값 256개를 받아 최종출력값인 0~9 레이블을 갖는\n",
        "# 10개의 출력값을 만듭니다.\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)\n",
        "print(W4)\n",
        "print(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_3:0' shape=(256, 10) dtype=float32_ref>\n",
            "Tensor(\"MatMul_1:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eLwt1o5eSQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 손실 함수와 AdamOptimizer를 이용한 최적화 함수를 만듭니다.\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "                        logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9WVjRmae2cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나중에 최적화 함수를 RMSPropOptimizer로 바꿔서 결과를 비교해보는 것도 좋을 듯\n",
        "\n",
        "# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnV3EFJrfFH_",
        "colab_type": "code",
        "outputId": "2503a501-f95b-4f88-a6b8-301691c56ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "########\n",
        "# 신경망 모델 학습\n",
        "#######\n",
        "\n",
        "# 이제 학습 시키고 결과를 확인 하는 코드 작성\n",
        "# 모델에 입력값을 전달하기 위해 MNIST 데이터를 28 x 28 형태로 재구성하는 부분을 아래와 같이 작성\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "  \n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(50):\n",
        "  total_cost = 0\n",
        "  \n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "  \n",
        "    _, cost_val = sess.run([optimizer, cost],\n",
        "                            feed_dict={X: batch_xs,\n",
        "                                       Y: batch_ys,\n",
        "                                       keep_prob: 0.7})\n",
        "    \n",
        "    total_cost += cost_val\n",
        "  \n",
        "  print('Epoch:', '%04d' % (epoch + 1),\n",
        "        'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "\n",
        "\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "print('정확도:', sess.run(accuracy,\n",
        "                         feed_dict={X: mnist.test.images.reshape(\n",
        "                                      -1, 28, 28, 1),\n",
        "                                    Y: mnist.test.labels,\n",
        "                                    keep_prob: 1}))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Avg. cost = 0.348\n",
            "Epoch: 0002 Avg. cost = 0.109\n",
            "Epoch: 0003 Avg. cost = 0.079\n",
            "Epoch: 0004 Avg. cost = 0.063\n",
            "Epoch: 0005 Avg. cost = 0.051\n",
            "Epoch: 0006 Avg. cost = 0.045\n",
            "Epoch: 0007 Avg. cost = 0.037\n",
            "Epoch: 0008 Avg. cost = 0.033\n",
            "Epoch: 0009 Avg. cost = 0.030\n",
            "Epoch: 0010 Avg. cost = 0.026\n",
            "Epoch: 0011 Avg. cost = 0.023\n",
            "Epoch: 0012 Avg. cost = 0.021\n",
            "Epoch: 0013 Avg. cost = 0.020\n",
            "Epoch: 0014 Avg. cost = 0.018\n",
            "Epoch: 0015 Avg. cost = 0.017\n",
            "Epoch: 0016 Avg. cost = 0.014\n",
            "Epoch: 0017 Avg. cost = 0.014\n",
            "Epoch: 0018 Avg. cost = 0.012\n",
            "Epoch: 0019 Avg. cost = 0.012\n",
            "Epoch: 0020 Avg. cost = 0.012\n",
            "Epoch: 0021 Avg. cost = 0.010\n",
            "Epoch: 0022 Avg. cost = 0.010\n",
            "Epoch: 0023 Avg. cost = 0.009\n",
            "Epoch: 0024 Avg. cost = 0.009\n",
            "Epoch: 0025 Avg. cost = 0.008\n",
            "Epoch: 0026 Avg. cost = 0.008\n",
            "Epoch: 0027 Avg. cost = 0.008\n",
            "Epoch: 0028 Avg. cost = 0.007\n",
            "Epoch: 0029 Avg. cost = 0.008\n",
            "Epoch: 0030 Avg. cost = 0.006\n",
            "Epoch: 0031 Avg. cost = 0.006\n",
            "Epoch: 0032 Avg. cost = 0.007\n",
            "Epoch: 0033 Avg. cost = 0.007\n",
            "Epoch: 0034 Avg. cost = 0.005\n",
            "Epoch: 0035 Avg. cost = 0.006\n",
            "Epoch: 0036 Avg. cost = 0.005\n",
            "Epoch: 0037 Avg. cost = 0.006\n",
            "Epoch: 0038 Avg. cost = 0.006\n",
            "Epoch: 0039 Avg. cost = 0.005\n",
            "Epoch: 0040 Avg. cost = 0.004\n",
            "Epoch: 0041 Avg. cost = 0.006\n",
            "Epoch: 0042 Avg. cost = 0.004\n",
            "Epoch: 0043 Avg. cost = 0.004\n",
            "Epoch: 0044 Avg. cost = 0.005\n",
            "Epoch: 0045 Avg. cost = 0.004\n",
            "Epoch: 0046 Avg. cost = 0.004\n",
            "Epoch: 0047 Avg. cost = 0.004\n",
            "Epoch: 0048 Avg. cost = 0.004\n",
            "Epoch: 0049 Avg. cost = 0.005\n",
            "Epoch: 0050 Avg. cost = 0.005\n",
            "최적화 완료!\n",
            "정확도: 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qBfp5SA5jjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}