{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[3분 딥러닝] 7장 - 이미지 인식의 은총알 CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihyunjeongme/deeplearning-tensflow-3min/blob/master/%5B3%EB%B6%84_%EB%94%A5%EB%9F%AC%EB%8B%9D%5D_7%EC%9E%A5_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EC%9D%B8%EC%8B%9D%EC%9D%98_%EC%9D%80%EC%B4%9D%EC%95%8C_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhSeGk2wcl0h",
        "colab_type": "text"
      },
      "source": [
        "# 합성곱 신경망(CNN)\n",
        "\n",
        "---\n",
        "\n",
        "CNN(Convolutional Neural Network)은 1998년 얀 레쿤 교수가 소개한 이래로 널리 사용되고 있는 신경망."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKZxsAa4OmWZ",
        "colab_type": "text"
      },
      "source": [
        "# 7.1 CNN 개념\n",
        "\n",
        "---\n",
        "\n",
        "- 컨볼루션 계층(합성곱 계층)과 풀링 계층으로 구성\n",
        "- 컨볼루션(2D): 2차원의 평면 행렬에서 지정한 영역의 값들을 하나의 값으로 압축하는 것.\n",
        "  - 단 하나의 값으로 압축할 때 컨볼루션 계층은 가중치와 편향을 적용하고, 풀링계층은 단순히 값들 중 하나를 선택해서 가져오는 방식\n",
        "- 윈도우: 지정한 크기의 영역\n",
        "- 스트라이드: 몇 칸씩 움직일지 정하는 값\n",
        "- 입력층의 윈도우를 은닉층의 뉴런 하나로 압축할 떄, 컨볼루션 계층에서는 윈도우 크기만큼의 가중치와 1개의 편향을 적용합니다.\n",
        "  - ex) 윈도우 크기가 3 x 3 이라면, 3 x 3개의 가중치와 1개의 편향이 필요합니다.\n",
        "  - 이 3 x 3개의 가중치와 1개의 편향을 커널 또는 필터 라고 하며\n",
        "  - 이 커널은 해당 은닉층을 만들기 위한 모든 윈도우에 공통으로 적용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOXoyi8QQjvh",
        "colab_type": "text"
      },
      "source": [
        "# 7.2 모델 구현하기\n",
        "\n",
        "---\n",
        "\n",
        "앞 장에서 사용한 MNIST 데이터를 CNN으로 학습시키는 모델을 만들어보면서 조금 더 자세히 알아보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQHAl6aXcHzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "cc5e8f9d-7b66-4680-a5bd-d16b7a95deb2"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybo-RdHdRK0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e25ca56-0edd-44af-d1f1-c88ae32f5a3b"
      },
      "source": [
        "# 앞 장에서 만든 모델에서는 입력값을 28 x 28짜리 하나로 구성했지만, CNN 모델에서는 \n",
        "# 앞서 설명한 것 처럼 2차원 평면으로 구성하므로 다음처럼 조금 더 직관적인 형태로 구성할수 있음.\n",
        "\n",
        "\n",
        "# X의 첫 번째 차원인 None은 입력 데이터의 개수. 마지막 차원인 1은 특징의 개수\n",
        "# MINIST 데이터는 회색조 이미지라 채널에 색상이 한개 뿐이므로 1을 사용\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "\n",
        "# 출력값인 10개의 분류와, 드롭아웃을 위한 keep_prob 플레이스 홀더도 정의\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder_18:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffdNasC_SBoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09ec101f-e287-4761-c985-8291d8158caa"
      },
      "source": [
        "# CNN 계층을 구성\n",
        "# 3 x 3 크기의 커널을 가진 컨볼루션 계층을 만듬\n",
        "# tf.nn.conv2d 함수를 사용하면 간단하게 구성할 수 있음.\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "L1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
        "L1 = tf.nn.relu(L1)\n",
        "\n",
        "# 28 x 28 ----> 32개\n",
        "print(L1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_8:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e_tegHnSlEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 입력층 X와 첫 번째 계층의 가중치 W1을 가지고, 오른쪽과 아래쪽 한칸씩 움직이는 32개의 커널을 가진\n",
        "# 컨볼루션 계층을 만들겠다는 코드\n",
        "# padding='SAME'은 커널 슬라이딩 시 이미지의 가장 외곽에서 한 칸 밖으로 움직이는 옵션\n",
        "# 이렇게 하면 이미지의 테두리까지도 조금 더 정확하게 평가 할 수 있습니다.\n",
        "# tf.nn.relu 활성화 함수를 통해 컨볼루션 계층 완성"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcCwimPCZpmZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c050ced-86f5-44a1-b2f6-d52057482fc7"
      },
      "source": [
        "# 풀링계층 만듬\n",
        "\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
        "                    padding='SAME')\n",
        "\n",
        "# 14 x 14 ----> 32개\n",
        "# 풀링계층에서 갯수가 줄음\n",
        "print(L1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool_5:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7lFdv4mZ2wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 앞서 만든 컨볼루션 계층을 입력층으로 사용하고, 커널 크기를 2 x 2 로 하는 풀링 계층을 만듬\n",
        "# strides=[1,2,2,1] 값은 슬라이딩 시 두칸씩 움직이겠다는 옵션"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcBqPYH5aMLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 두번째 계층을 동일한 방식으로 구성\n",
        "# 3 x 3 크기의 커널 64개로 구성한 컬볼루션 계층과\n",
        "# 3, 3, 32, 64 여기에서 32는 앞 서 구성한 첫 번째 컨볼루션 계층의 커널 개수\n",
        "# 이것은 출력층의 개수이며 또한 첫 번째 컨볼루션 계층이 찾아낸 이미지의 특징 개수\n",
        "\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "\n",
        "# 2 x 2 크기의 풀링 계층으로 구성\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1],\n",
        "                    padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1-nBGrkbrRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이제 추출한 특징들을 이용해 10개의 분류를 만들어내는 계층을 구성해보겠습니다.\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
        "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
        "L3 = tf.matmul(L3, W3)\n",
        "L3 = tf.nn.relu(L3)\n",
        "L3 = tf.nn.dropout(L3, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTa16iPkc91x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 먼저 10개의 분류는 1차원 배열이므로 차원을 줄이는 단계를 거쳐야 합니다.\n",
        "# 직전 풀링 계층 크기가 7 x 7 x 64 이므로 tf.reshpae 함수를 이용해 7 x 7 x 64 크기의 1차원\n",
        "# 계층으로 만들고, 이 배열 전체를 최종 출력값의 중간 단계 인 256개의 뉴런으로 연결하는 신경망을 만듬.\n",
        "\n",
        "# 이처럼 인접한 계층의 모든 뉴런과 상호 연결된 계층을 '완전연결계층' 이라고 함.\n",
        "# 이번 계층에서는 과적합을 막아주는 드롭아웃 기법 사용"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO9TUPa-d9SG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a33dd4b0-8469-4589-8f8c-2a1c95d0a211"
      },
      "source": [
        "# 모델 구성의 마지막으로 직전의 은닉층인 L3의 출력값 256개를 받아 최종출력값인 0~9 레이블을 갖는\n",
        "# 10개의 출력값을 만듭니다.\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)\n",
        "print(W4)\n",
        "print(model)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable_17:0' shape=(256, 10) dtype=float32_ref>\n",
            "Tensor(\"MatMul_7:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eLwt1o5eSQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 손실 함수와 AdamOptimizer를 이용한 최적화 함수를 만듭니다.\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "                        logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9WVjRmae2cJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 나중에 최적화 함수를 RMSPropOptimizer로 바꿔서 결과를 비교해보는 것도 좋을 듯\n",
        "\n",
        "# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnV3EFJrfFH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "c86f08f1-6bf6-40ae-b7f5-2ac663fc0963"
      },
      "source": [
        "# 이제 학습 시키고 결과를 확인 하는 코드 작성\n",
        "# 모델에 입력값을 전달하기 위해 MNIST 데이터를 28 x 28 형태로 재구성하는 부분을 아래와 같이 작성\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "\n",
        "for epoch in range(50):\n",
        "  total_cost = 0\n",
        "  \n",
        "  for i in range(total_batch):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "    batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "  \n",
        "    _, cost_val = sess.run([optimizer, cost],\n",
        "                            feed_dict={X: batch_xs,\n",
        "                                       Y: batch_ys,\n",
        "                                       keep_prob: 0.7})\n",
        "    \n",
        "    total_cost += cost_val\n",
        "  \n",
        "  print('Epoch:', '%04d' % (epoch + 1),\n",
        "        'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
        "\n",
        "print('최적화 완료!')\n",
        "\n",
        "\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "\n",
        "print('정확도:', sess.run(accuracy,\n",
        "                         feed_dict={X: mnist.test.images.reshape(\n",
        "                                      -1, 28, 28, 1),\n",
        "                                    Y: mnist.test.labels,\n",
        "                                    keep_prob: 1}))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Avg. cost = 0.342\n",
            "Epoch: 0002 Avg. cost = 0.109\n",
            "Epoch: 0003 Avg. cost = 0.076\n",
            "Epoch: 0004 Avg. cost = 0.059\n",
            "Epoch: 0005 Avg. cost = 0.050\n",
            "Epoch: 0006 Avg. cost = 0.042\n",
            "Epoch: 0007 Avg. cost = 0.037\n",
            "Epoch: 0008 Avg. cost = 0.030\n",
            "Epoch: 0009 Avg. cost = 0.028\n",
            "Epoch: 0010 Avg. cost = 0.026\n",
            "Epoch: 0011 Avg. cost = 0.023\n",
            "Epoch: 0012 Avg. cost = 0.019\n",
            "Epoch: 0013 Avg. cost = 0.019\n",
            "Epoch: 0014 Avg. cost = 0.017\n",
            "Epoch: 0015 Avg. cost = 0.017\n",
            "Epoch: 0016 Avg. cost = 0.014\n",
            "Epoch: 0017 Avg. cost = 0.014\n",
            "Epoch: 0018 Avg. cost = 0.012\n",
            "Epoch: 0019 Avg. cost = 0.011\n",
            "Epoch: 0020 Avg. cost = 0.010\n",
            "Epoch: 0021 Avg. cost = 0.010\n",
            "Epoch: 0022 Avg. cost = 0.010\n",
            "Epoch: 0023 Avg. cost = 0.009\n",
            "Epoch: 0024 Avg. cost = 0.009\n",
            "Epoch: 0025 Avg. cost = 0.009\n",
            "Epoch: 0026 Avg. cost = 0.007\n",
            "Epoch: 0027 Avg. cost = 0.008\n",
            "Epoch: 0028 Avg. cost = 0.007\n",
            "Epoch: 0029 Avg. cost = 0.007\n",
            "Epoch: 0030 Avg. cost = 0.006\n",
            "Epoch: 0031 Avg. cost = 0.008\n",
            "Epoch: 0032 Avg. cost = 0.005\n",
            "Epoch: 0033 Avg. cost = 0.005\n",
            "Epoch: 0034 Avg. cost = 0.006\n",
            "Epoch: 0035 Avg. cost = 0.006\n",
            "Epoch: 0036 Avg. cost = 0.007\n",
            "Epoch: 0037 Avg. cost = 0.005\n",
            "Epoch: 0038 Avg. cost = 0.005\n",
            "Epoch: 0039 Avg. cost = 0.004\n",
            "Epoch: 0040 Avg. cost = 0.004\n",
            "Epoch: 0041 Avg. cost = 0.006\n",
            "Epoch: 0042 Avg. cost = 0.005\n",
            "Epoch: 0043 Avg. cost = 0.004\n",
            "Epoch: 0044 Avg. cost = 0.004\n",
            "Epoch: 0045 Avg. cost = 0.005\n",
            "Epoch: 0046 Avg. cost = 0.005\n",
            "Epoch: 0047 Avg. cost = 0.004\n",
            "Epoch: 0048 Avg. cost = 0.003\n",
            "Epoch: 0049 Avg. cost = 0.004\n",
            "Epoch: 0050 Avg. cost = 0.004\n",
            "최적화 완료!\n",
            "정확도: 0.9929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6-SlO_gfnOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZrLWPzSla0c",
        "colab_type": "text"
      },
      "source": [
        "# 7.3 고수준 API\n",
        "\n",
        "---\n",
        "\n",
        "layers 모듈을 이용하여 앞서 만든 CNN 모델을 조금 더 간단하게 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCKFvRSBlnUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}